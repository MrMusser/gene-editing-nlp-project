{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project: Build a Classifer to Determine Whether a Text Was Written by Scientists or Ethicists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>sub-type</th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>word_count</th>\n",
       "      <th>file_name</th>\n",
       "      <th>eth_or_sci</th>\n",
       "      <th>raw</th>\n",
       "      <th>no_nums</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gov</td>\n",
       "      <td>unclear</td>\n",
       "      <td>2015</td>\n",
       "      <td>international</td>\n",
       "      <td>international summit on human genome editing</td>\n",
       "      <td>statement of the first summit on human genome ...</td>\n",
       "      <td>957</td>\n",
       "      <td>First Summit Statement.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>On Human Gene Editing:\\nInternational Summit S...</td>\n",
       "      <td>On Human Gene Editing:\\nInternational Summit S...</td>\n",
       "      <td>on human gene editing international summit sta...</td>\n",
       "      <td>[on, human, gene, editing, international, summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gov</td>\n",
       "      <td>eth</td>\n",
       "      <td>2015</td>\n",
       "      <td>europe</td>\n",
       "      <td>council of europe committee on bioethics</td>\n",
       "      <td>statement on genome editing technologies</td>\n",
       "      <td>626</td>\n",
       "      <td>Council of Europe Bioethics.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\n \\n\\n \\n\\nStrasbourg, 2 December 2015 DH-...</td>\n",
       "      <td>\\n\\n \\n\\n \\n\\nStrasbourg,   December   DH-BIO...</td>\n",
       "      <td>strasbourg december dh bio inf coe logo fil b...</td>\n",
       "      <td>[strasbourg, december, dh, bio, inf, coe, logo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gov</td>\n",
       "      <td>unclear</td>\n",
       "      <td>2015</td>\n",
       "      <td>germany</td>\n",
       "      <td>berlin-brandenburg academy of sciences and hum...</td>\n",
       "      <td>human genome surgery – towards a responsible e...</td>\n",
       "      <td>6502</td>\n",
       "      <td>Brandenburg.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>HUMAN GENOME SURGERY � \\nTOWARDS A RESPONSIBLE...</td>\n",
       "      <td>HUMAN GENOME SURGERY � \\nTOWARDS A RESPONSIBLE...</td>\n",
       "      <td>human genome surgery towards a responsible eva...</td>\n",
       "      <td>[human, genome, surgery, towards, a, responsib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gov</td>\n",
       "      <td>sci</td>\n",
       "      <td>2015</td>\n",
       "      <td>germany</td>\n",
       "      <td>german national academy of sciences</td>\n",
       "      <td>statement. The opportunities and limits of gen...</td>\n",
       "      <td>4761</td>\n",
       "      <td>Leopoldina.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>The opportunities and limits of genome editinT...</td>\n",
       "      <td>The opportunities and limits of genome editinT...</td>\n",
       "      <td>the opportunities and limits of genome editint...</td>\n",
       "      <td>[the, opportunities, and, limits, of, genome, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gov</td>\n",
       "      <td>eth</td>\n",
       "      <td>2015</td>\n",
       "      <td>international</td>\n",
       "      <td>unesco international bioethics committee</td>\n",
       "      <td>report of the ibc on updating its reflection o...</td>\n",
       "      <td>17046</td>\n",
       "      <td>UNESCO.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\nDistribution: limited \\n\\nSHS/YES/IBC-22/...</td>\n",
       "      <td>\\n\\nDistribution: limited \\n\\nSHS/YES/IBC- / ...</td>\n",
       "      <td>distribution limited shs yes ibc rev paris oc...</td>\n",
       "      <td>[distribution, limited, shs, yes, ibc, rev, pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type sub-type  year        country  \\\n",
       "0  gov  unclear  2015  international   \n",
       "1  gov      eth  2015         europe   \n",
       "2  gov  unclear  2015        germany   \n",
       "3  gov      sci  2015        germany   \n",
       "4  gov      eth  2015  international   \n",
       "\n",
       "                                              author  \\\n",
       "0       international summit on human genome editing   \n",
       "1           council of europe committee on bioethics   \n",
       "2  berlin-brandenburg academy of sciences and hum...   \n",
       "3                german national academy of sciences   \n",
       "4           unesco international bioethics committee   \n",
       "\n",
       "                                               title  word_count  \\\n",
       "0  statement of the first summit on human genome ...         957   \n",
       "1           statement on genome editing technologies         626   \n",
       "2  human genome surgery – towards a responsible e...        6502   \n",
       "3  statement. The opportunities and limits of gen...        4761   \n",
       "4  report of the ibc on updating its reflection o...       17046   \n",
       "\n",
       "                         file_name  eth_or_sci  \\\n",
       "0       First Summit Statement.txt           2   \n",
       "1  Council of Europe Bioethics.txt           0   \n",
       "2                  Brandenburg.txt           2   \n",
       "3                   Leopoldina.txt           1   \n",
       "4                       UNESCO.txt           0   \n",
       "\n",
       "                                                 raw  \\\n",
       "0  On Human Gene Editing:\\nInternational Summit S...   \n",
       "1   \\n\\n \\n\\n \\n\\nStrasbourg, 2 December 2015 DH-...   \n",
       "2  HUMAN GENOME SURGERY � \\nTOWARDS A RESPONSIBLE...   \n",
       "3  The opportunities and limits of genome editinT...   \n",
       "4   \\n\\nDistribution: limited \\n\\nSHS/YES/IBC-22/...   \n",
       "\n",
       "                                             no_nums  \\\n",
       "0  On Human Gene Editing:\\nInternational Summit S...   \n",
       "1   \\n\\n \\n\\n \\n\\nStrasbourg,   December   DH-BIO...   \n",
       "2  HUMAN GENOME SURGERY � \\nTOWARDS A RESPONSIBLE...   \n",
       "3  The opportunities and limits of genome editinT...   \n",
       "4   \\n\\nDistribution: limited \\n\\nSHS/YES/IBC- / ...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  on human gene editing international summit sta...   \n",
       "1   strasbourg december dh bio inf coe logo fil b...   \n",
       "2  human genome surgery towards a responsible eva...   \n",
       "3  the opportunities and limits of genome editint...   \n",
       "4   distribution limited shs yes ibc rev paris oc...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [on, human, gene, editing, international, summ...  \n",
       "1  [strasbourg, december, dh, bio, inf, coe, logo...  \n",
       "2  [human, genome, surgery, towards, a, responsib...  \n",
       "3  [the, opportunities, and, limits, of, genome, ...  \n",
       "4  [distribution, limited, shs, yes, ibc, rev, pa...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOTE: Text has not been lemmatized\n",
    "\n",
    "meta = pd.read_csv('metadata.csv')\n",
    "meta['eth_or_sci'] = [0 if r=='eth' else 1 if r=='sci' else 2 for r in meta['sub-type']]\n",
    "meta['raw'] = [open(x).read() for x in meta['file_name']]\n",
    "meta['no_nums'] = [re.sub('\\d+', ' ', y) for y in meta['raw']]\n",
    "meta['clean'] = [re.sub('\\W+', ' ', a).lower() for a in meta['no_nums']]\n",
    "meta['tokens'] = [nltk.word_tokenize(b) for b in meta['clean']]\n",
    "\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17580 4396 17580 4396\n"
     ]
    }
   ],
   "source": [
    "def build_sentences(type):\n",
    "    sentences_list = []\n",
    "    if type == 'eth': \n",
    "        eth_vals = meta[meta['eth_or_sci'] == 0].reset_index()\n",
    "        for index in range(len(eth_vals)):\n",
    "            sentences = nltk.sent_tokenize(eth_vals['no_nums'][index])\n",
    "            for sentence in sentences: \n",
    "                sentence_clean = re.sub('\\W+', ' ', sentence).lower()\n",
    "                sentences_list.append(sentence_clean)\n",
    "        return sentences_list\n",
    "    if type == 'sci': \n",
    "        sci_vals = meta[meta['eth_or_sci'] == 1].reset_index()\n",
    "        for index in range(len(sci_vals)):\n",
    "            sentences = nltk.sent_tokenize(sci_vals['no_nums'][index])\n",
    "            for sentence in sentences: \n",
    "                sentence_clean = re.sub('\\W+', ' ', sentence).lower()\n",
    "                sentences_list.append(sentence_clean)\n",
    "        return sentences_list\n",
    "\n",
    "eth_sentences = build_sentences('eth')\n",
    "sci_sentences = build_sentences('sci')\n",
    "X = eth_sentences + sci_sentences\n",
    "Y = [0] * len(eth_sentences) + [1] * len(sci_sentences)\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "print(len(train_x), len(test_x), len(train_y), len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"gov_eth_sentences.txt\", \"wt\")\n",
    "n = text_file.write('\\n'.join(eth_sentences))\n",
    "text_file.close()\n",
    "\n",
    "text_file = open('gov_sci_sentences.txt', 'wt')\n",
    "n = text_file.write('\\n'.join(sci_sentences))\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(meta['clean'])\n",
    "\n",
    "Train_X_Tfidf = Tfidf_vect.transform(train_x)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(test_x)\n",
    "\n",
    "print('\\n\\n\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  76.52411282984531\n",
      "SVM Accuracy Score ->  77.88898999090081\n"
     ]
    }
   ],
   "source": [
    "#Using Naive Bayes Classifier\n",
    "\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(Train_X_Tfidf, train_y)\n",
    "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, test_y)*100)\n",
    "\n",
    "\n",
    "#Using Support Vector Machine\n",
    "\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(Train_X_Tfidf, train_y)\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, test_y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
