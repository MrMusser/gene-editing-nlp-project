{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "print('\\n\\n\\n\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>sub-type</th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>word_count</th>\n",
       "      <th>file_name</th>\n",
       "      <th>raw</th>\n",
       "      <th>no_nums</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gov</td>\n",
       "      <td>unclear</td>\n",
       "      <td>2015</td>\n",
       "      <td>international</td>\n",
       "      <td>international summit on human genome editing</td>\n",
       "      <td>statement of the first summit on human genome ...</td>\n",
       "      <td>957</td>\n",
       "      <td>First Summit Statement.txt</td>\n",
       "      <td>On Human Gene Editing:\\nInternational Summit S...</td>\n",
       "      <td>On Human Gene Editing:\\nInternational Summit S...</td>\n",
       "      <td>On Human Gene Editing : International Summit S...</td>\n",
       "      <td>on human gene editing international summit sta...</td>\n",
       "      <td>[on, human, gene, editing, international, summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gov</td>\n",
       "      <td>eth</td>\n",
       "      <td>2015</td>\n",
       "      <td>europe</td>\n",
       "      <td>council of europe committee on bioethics</td>\n",
       "      <td>statement on genome editing technologies</td>\n",
       "      <td>626</td>\n",
       "      <td>Council of Europe Bioethics.txt</td>\n",
       "      <td>\\n\\n \\n\\n \\n\\nStrasbourg, 2 December 2015 DH-...</td>\n",
       "      <td>\\n\\n \\n\\n \\n\\nStrasbourg,   December   DH-BIO...</td>\n",
       "      <td>Strasbourg , December DH-BIO/INF ( ) COE-Logo-...</td>\n",
       "      <td>strasbourg december dh bio inf coe logo fil bw...</td>\n",
       "      <td>[strasbourg, december, dh, bio, inf, coe, logo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gov</td>\n",
       "      <td>unclear</td>\n",
       "      <td>2015</td>\n",
       "      <td>germany</td>\n",
       "      <td>berlin-brandenburg academy of sciences and hum...</td>\n",
       "      <td>human genome surgery – towards a responsible e...</td>\n",
       "      <td>6502</td>\n",
       "      <td>Brandenburg.txt</td>\n",
       "      <td>HUMAN GENOME SURGERY � \\nTOWARDS A RESPONSIBLE...</td>\n",
       "      <td>HUMAN GENOME SURGERY � \\nTOWARDS A RESPONSIBLE...</td>\n",
       "      <td>HUMAN GENOME SURGERY � TOWARDS A RESPONSIBLE E...</td>\n",
       "      <td>human genome surgery towards a responsible eva...</td>\n",
       "      <td>[human, genome, surgery, towards, a, responsib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gov</td>\n",
       "      <td>sci</td>\n",
       "      <td>2015</td>\n",
       "      <td>germany</td>\n",
       "      <td>german national academy of sciences</td>\n",
       "      <td>statement. The opportunities and limits of gen...</td>\n",
       "      <td>4761</td>\n",
       "      <td>Leopoldina.txt</td>\n",
       "      <td>The opportunities and limits of genome editinT...</td>\n",
       "      <td>The opportunities and limits of genome editinT...</td>\n",
       "      <td>The opportunity and limit of genome editinThe ...</td>\n",
       "      <td>the opportunity and limit of genome editinthe ...</td>\n",
       "      <td>[the, opportunity, and, limit, of, genome, edi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gov</td>\n",
       "      <td>eth</td>\n",
       "      <td>2015</td>\n",
       "      <td>international</td>\n",
       "      <td>unesco international bioethics committee</td>\n",
       "      <td>report of the ibc on updating its reflection o...</td>\n",
       "      <td>17046</td>\n",
       "      <td>UNESCO.txt</td>\n",
       "      <td>\\n\\nDistribution: limited \\n\\nSHS/YES/IBC-22/...</td>\n",
       "      <td>\\n\\nDistribution: limited \\n\\nSHS/YES/IBC- / ...</td>\n",
       "      <td>Distribution : limited SHS/YES/IBC- / / REV . ...</td>\n",
       "      <td>distribution limited shs yes ibc rev paris oct...</td>\n",
       "      <td>[distribution, limited, shs, yes, ibc, rev, pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type sub-type  year        country  \\\n",
       "0  gov  unclear  2015  international   \n",
       "1  gov      eth  2015         europe   \n",
       "2  gov  unclear  2015        germany   \n",
       "3  gov      sci  2015        germany   \n",
       "4  gov      eth  2015  international   \n",
       "\n",
       "                                              author  \\\n",
       "0       international summit on human genome editing   \n",
       "1           council of europe committee on bioethics   \n",
       "2  berlin-brandenburg academy of sciences and hum...   \n",
       "3                german national academy of sciences   \n",
       "4           unesco international bioethics committee   \n",
       "\n",
       "                                               title  word_count  \\\n",
       "0  statement of the first summit on human genome ...         957   \n",
       "1           statement on genome editing technologies         626   \n",
       "2  human genome surgery – towards a responsible e...        6502   \n",
       "3  statement. The opportunities and limits of gen...        4761   \n",
       "4  report of the ibc on updating its reflection o...       17046   \n",
       "\n",
       "                         file_name  \\\n",
       "0       First Summit Statement.txt   \n",
       "1  Council of Europe Bioethics.txt   \n",
       "2                  Brandenburg.txt   \n",
       "3                   Leopoldina.txt   \n",
       "4                       UNESCO.txt   \n",
       "\n",
       "                                                 raw  \\\n",
       "0  On Human Gene Editing:\\nInternational Summit S...   \n",
       "1   \\n\\n \\n\\n \\n\\nStrasbourg, 2 December 2015 DH-...   \n",
       "2  HUMAN GENOME SURGERY � \\nTOWARDS A RESPONSIBLE...   \n",
       "3  The opportunities and limits of genome editinT...   \n",
       "4   \\n\\nDistribution: limited \\n\\nSHS/YES/IBC-22/...   \n",
       "\n",
       "                                             no_nums  \\\n",
       "0  On Human Gene Editing:\\nInternational Summit S...   \n",
       "1   \\n\\n \\n\\n \\n\\nStrasbourg,   December   DH-BIO...   \n",
       "2  HUMAN GENOME SURGERY � \\nTOWARDS A RESPONSIBLE...   \n",
       "3  The opportunities and limits of genome editinT...   \n",
       "4   \\n\\nDistribution: limited \\n\\nSHS/YES/IBC- / ...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  On Human Gene Editing : International Summit S...   \n",
       "1  Strasbourg , December DH-BIO/INF ( ) COE-Logo-...   \n",
       "2  HUMAN GENOME SURGERY � TOWARDS A RESPONSIBLE E...   \n",
       "3  The opportunity and limit of genome editinThe ...   \n",
       "4  Distribution : limited SHS/YES/IBC- / / REV . ...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  on human gene editing international summit sta...   \n",
       "1  strasbourg december dh bio inf coe logo fil bw...   \n",
       "2  human genome surgery towards a responsible eva...   \n",
       "3  the opportunity and limit of genome editinthe ...   \n",
       "4  distribution limited shs yes ibc rev paris oct...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [on, human, gene, editing, international, summ...  \n",
       "1  [strasbourg, december, dh, bio, inf, coe, logo...  \n",
       "2  [human, genome, surgery, towards, a, responsib...  \n",
       "3  [the, opportunity, and, limit, of, genome, edi...  \n",
       "4  [distribution, limited, shs, yes, ibc, rev, pa...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatize_text(text):\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    preprocessed_text= ' '.join(tokens)\n",
    "    return preprocessed_text \n",
    "\n",
    "\n",
    "meta = pd.read_csv('metadata.csv')\n",
    "meta['raw'] = [open(x).read() for x in meta['file_name']]\n",
    "meta['no_nums'] = [re.sub('\\d+', ' ', y) for y in meta['raw']]\n",
    "meta['lemmatized'] = [lemmatize_text(z) for z in meta['no_nums']]\n",
    "meta['clean'] = [re.sub('\\W+', ' ', a).lower() for a in meta['lemmatized']]\n",
    "meta['tokens'] = [nltk.word_tokenize(b) for b in meta['clean']]\n",
    "\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def build_file(df, indices, how):\n",
    "    if how == 'clean':\n",
    "        string_clean = []\n",
    "        for i in indices:\n",
    "            string_clean.extend(df['clean'][i])\n",
    "        string_clean = (''.join(string_clean))\n",
    "        return string_clean\n",
    "    if how == 'tokens':\n",
    "        list_tokens = []\n",
    "        for i in indices:\n",
    "            list_tokens.extend(df['tokens'][i])\n",
    "        return list_tokens\n",
    "\n",
    "def create_sentences(df, indices):\n",
    "    sentences_list = []\n",
    "    for index in indices:\n",
    "        sentences = nltk.sent_tokenize(df['lemmatized'][index])\n",
    "        for sentence in sentences:\n",
    "            sentence_clean = re.sub('\\W+', ' ', sentence).lower()\n",
    "            sentences_list.append(sentence_clean)\n",
    "    return sentences_list\n",
    "    \n",
    "def count_phrase(phrase, file):\n",
    "    counter = file.count(phrase)\n",
    "    return counter\n",
    "\n",
    "def count_phrase_pct(phrase, file_clean, file_tokens):\n",
    "    return count_phrase(phrase, file_clean) / len(file_tokens)\n",
    "\n",
    "print('\\n\\n\\n\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10173 12388 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eth = meta[meta['sub-type'] == 'eth'].reset_index()\n",
    "sci = meta[meta['sub-type'] == 'sci'].reset_index()\n",
    "eth_sentences = create_sentences(eth, range(len(eth)))\n",
    "sci_sentences = create_sentences(sci, range(len(sci)))\n",
    "print(len(eth_sentences), len(sci_sentences), '\\n\\n\\n\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "58\n",
      "0.2054794520547945\n",
      "105\n",
      "715\n",
      "0.12804878048780488\n",
      "227\n",
      "1649\n",
      "0.12100213219616204\n",
      "512\n",
      "810\n",
      "0.38729198184568836\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Everything from this point forward is just playing around and looking for patterns.\n",
    "\n",
    "\n",
    "data_2015 = meta[meta['year'] == 2015].reset_index()\n",
    "data_2016 = meta[meta['year'] == 2016].reset_index()\n",
    "data_2017 = meta[meta['year'] == 2017].reset_index()\n",
    "data_2018 = meta[meta['year'] == 2018].reset_index()\n",
    "\n",
    "societal_2015 = count_phrase('gene editing', build_file(data_2015, range(len(data_2015)), 'clean'))\n",
    "scientific_2015 = count_phrase('genome editing', build_file(data_2015, range(len(data_2015)), 'clean'))\n",
    "print(societal_2015)\n",
    "print(scientific_2015)\n",
    "print(societal_2015 / (scientific_2015 + societal_2015))\n",
    "\n",
    "societal_2016 = count_phrase('gene editing', build_file(data_2016, range(len(data_2016)), 'clean'))\n",
    "scientific_2016 = count_phrase('genome editing', build_file(data_2016, range(len(data_2016)), 'clean'))\n",
    "print(societal_2016)\n",
    "print(scientific_2016)\n",
    "print(societal_2016 / (scientific_2016 + societal_2016))\n",
    "\n",
    "societal_2017 = count_phrase('gene editing', build_file(data_2017, range(len(data_2017)), 'clean'))\n",
    "scientific_2017 = count_phrase('genome editing', build_file(data_2017, range(len(data_2017)), 'clean'))\n",
    "print(societal_2017)\n",
    "print(scientific_2017)\n",
    "print(societal_2017 / (scientific_2017 + societal_2017))\n",
    "\n",
    "societal_2018 = count_phrase('gene editing', build_file(data_2018, range(len(data_2018)), 'clean'))\n",
    "scientific_2018 = count_phrase('genome editing', build_file(data_2018, range(len(data_2018)), 'clean'))\n",
    "print(societal_2018)\n",
    "print(scientific_2018)\n",
    "print(societal_2018 / (scientific_2018 + societal_2018))\n",
    "\n",
    "\n",
    "print('\\n\\n\\n\\n\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of 'Gene Editing': 0.0014952080236448264\n",
      "Frequency of 'Genome Editing': 0.005655332792575135\n",
      "Frequency of 'Germline Editing': 0.00013402912435465846\n",
      "Frequency of 'Societal Consensus': 3.1331483615374705e-05\n",
      "Frequency of 'Scientific Consensus': 3.4812759572638562e-06\n",
      "Relative Frequency of 'Societal' vs. 'Scientific' Consensus: 9.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Outdated code. Still functional, but is not based on newer, more versatile pandas code\n",
    "\n",
    "\n",
    "\n",
    "def count_phrase(phrase):\n",
    "    counter = master_clean.count(phrase)\n",
    "    return counter\n",
    "\n",
    "#def join_master(master_clean):\n",
    "    #start = ''\n",
    "    #for i in range(10):\n",
    "        #start = start + master_clean[i]\n",
    "    #return start\n",
    "\n",
    "#master_clean = join_master(master_clean)\n",
    "\n",
    "print(\"Frequency of 'Gene Editing': \" + str(count_phrase('gene editing')/len(master_tokens)))\n",
    "print(\"Frequency of 'Genome Editing': \" + str(count_phrase('genome editing')/len(master_tokens)))\n",
    "print(\"Frequency of 'Germline Editing': \" + str(count_phrase('germline editing')/len(master_tokens)))\n",
    "print(\"Frequency of 'Societal Consensus': \" + str(count_phrase('societal consensus')/len(master_tokens)))\n",
    "print(\"Frequency of 'Scientific Consensus': \" + str(count_phrase('scientific consensus')/len(master_tokens)))\n",
    "\n",
    "print(\"Relative Frequency of 'Societal' vs. 'Scientific' Consensus: \" + \n",
    "     str(count_phrase('societal consensus') / count_phrase('scientific consensus')))\n",
    "\n",
    "print('\\n\\n\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('human', 'genome', 'editing'), 676), (('national', 'academy', 'sciences'), 426), (('genome', 'editing', 'science'), 331), (('editing', 'science', 'ethics'), 331), (('science', 'ethics', 'governance'), 331), (('copyright', 'national', 'academy'), 330), (('academy', 'sciences', 'rights'), 330), (('sciences', 'rights', 'reserved'), 330), (('rights', 'reserved', 'human'), 307), (('reserved', 'human', 'genome'), 307), (('genome', 'editing', 'human'), 242), (('heritable', 'genome', 'editing'), 240), (('editing', 'human', 'reproduction'), 203), (('governance', 'human', 'genome'), 155), (('nuffield', 'council', 'bioethics'), 145), (('ethics', 'governance', 'human'), 142), (('germline', 'genetic', 'modification'), 128), (('retrieved', 'july', 'from'), 123), (('gene', 'technology', 'regulator'), 119), (('genome', 'editing', 'interventions'), 113)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_over_4 = re.findall(r'\\w\\w\\w\\w+', master_clean)\n",
    "trigrams = ngrams(words_over_4, 3)\n",
    "trigrams_frequency = Counter(trigrams)\n",
    "print(trigrams_frequency.most_common(20))\n",
    "print('\\n\\n\\n\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
